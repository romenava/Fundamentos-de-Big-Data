{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5329de77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://L2108017.bosonit.local:4041\n",
       "SparkContext available as 'sc' (version = 3.0.3, master = local[*], app id = local-1634196002505)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.SparkSession\r\n",
       "import org.apache.spark.sql.functions.count\r\n",
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@368960df\r\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.sql.functions.count\n",
    "// Build a SparkSession using the SparkSession APIs.\n",
    "// If one does not exist, then create an instance. There\n",
    "// can only be one SparkSession per JVM.\n",
    "val spark = SparkSession\n",
    " .builder\n",
    " .appName(\"ScalaMnMCount\")\n",
    " .getOrCreate()\n",
    "// Get the M&M data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29671f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-----+\n",
      "|State|Color |Count|\n",
      "+-----+------+-----+\n",
      "|TX   |Red   |20   |\n",
      "|NV   |Blue  |66   |\n",
      "|CO   |Blue  |79   |\n",
      "|OR   |Blue  |71   |\n",
      "|WA   |Yellow|93   |\n",
      "+-----+------+-----+\n",
      "only showing top 5 rows\n",
      "\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "mnmFile: String = C:/Users/alvaro.romero/Big_Data/LearningSparkV2-master/chapter2/py/src/data/mnm_dataset.csv\r\n",
       "mnmDF: org.apache.spark.sql.DataFrame = [State: string, Color: string ... 1 more field]\r\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "    // get the M&M data set file name\n",
    "    val mnmFile = \"C:/Users/alvaro.romero/Big_Data/LearningSparkV2-master/chapter2/py/src/data/mnm_dataset.csv\"\n",
    "    // read the file into a Spark DataFrame\n",
    "    val mnmDF = spark.read.format(\"csv\")\n",
    "      .option(\"header\", \"true\")\n",
    "      .option(\"inferSchema\", \"true\")\n",
    "      .load(mnmFile)\n",
    "    // display DataFrame\n",
    "    mnmDF.show(5, false)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fec1106",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Crear TempView\n",
    "mnmDF.createOrReplaceTempView(\"mnmDFView\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ba6c217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-----+\n",
      "|State| Color|Total|\n",
      "+-----+------+-----+\n",
      "|   CA|Yellow| 1807|\n",
      "|   WA| Green| 1779|\n",
      "|   OR|Orange| 1743|\n",
      "|   TX| Green| 1737|\n",
      "|   TX|   Red| 1725|\n",
      "|   CA| Green| 1723|\n",
      "|   CO|Yellow| 1721|\n",
      "|   CA| Brown| 1718|\n",
      "|   CO| Green| 1713|\n",
      "|   NV|Orange| 1712|\n",
      "|   TX|Yellow| 1703|\n",
      "|   NV| Green| 1698|\n",
      "|   AZ| Brown| 1698|\n",
      "|   CO|  Blue| 1695|\n",
      "|   WY| Green| 1695|\n",
      "|   NM|   Red| 1690|\n",
      "|   AZ|Orange| 1689|\n",
      "|   NM|Yellow| 1688|\n",
      "|   NM| Brown| 1687|\n",
      "|   UT|Orange| 1684|\n",
      "|   NM| Green| 1682|\n",
      "|   UT|   Red| 1680|\n",
      "|   AZ| Green| 1676|\n",
      "|   NV|Yellow| 1675|\n",
      "|   NV|  Blue| 1673|\n",
      "|   WA|   Red| 1671|\n",
      "|   WY|   Red| 1670|\n",
      "|   WA| Brown| 1669|\n",
      "|   NM|Orange| 1665|\n",
      "|   WY|  Blue| 1664|\n",
      "|   WA|Yellow| 1663|\n",
      "|   WA|Orange| 1658|\n",
      "|   CA|Orange| 1657|\n",
      "|   NV| Brown| 1657|\n",
      "|   CA|   Red| 1656|\n",
      "|   CO| Brown| 1656|\n",
      "|   UT|  Blue| 1655|\n",
      "|   AZ|Yellow| 1654|\n",
      "|   TX|Orange| 1652|\n",
      "|   AZ|   Red| 1648|\n",
      "|   OR|  Blue| 1646|\n",
      "|   UT|Yellow| 1645|\n",
      "|   OR|   Red| 1645|\n",
      "|   CO|Orange| 1642|\n",
      "|   TX| Brown| 1641|\n",
      "|   NM|  Blue| 1638|\n",
      "|   AZ|  Blue| 1636|\n",
      "|   OR| Green| 1634|\n",
      "|   UT| Brown| 1631|\n",
      "|   WY|Yellow| 1626|\n",
      "|   WA|  Blue| 1625|\n",
      "|   CO|   Red| 1624|\n",
      "|   OR| Brown| 1621|\n",
      "|   TX|  Blue| 1614|\n",
      "|   OR|Yellow| 1614|\n",
      "|   NV|   Red| 1610|\n",
      "|   CA|  Blue| 1603|\n",
      "|   WY|Orange| 1595|\n",
      "|   UT| Green| 1591|\n",
      "|   WY| Brown| 1532|\n",
      "+-----+------+-----+\n",
      "\n",
      "Total Rows = 60\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "countMnMDF: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [State: string, Color: string ... 1 more field]\r\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    // aggregate count of all colors and groupBy state and color\n",
    "    // orderBy descending order\n",
    "\n",
    "    val countMnMDF = mnmDF\n",
    "     .select(\"State\", \"Color\", \"Count\")\n",
    "     .groupBy(\"State\", \"Color\")\n",
    "     .agg(count(\"Count\").alias(\"Total\"))\n",
    "     .orderBy(desc(\"Total\"))\n",
    "\n",
    "    // show all the resulting aggregation for all the dates and colors\n",
    "    countMnMDF.show(60)\n",
    "    println(s\"Total Rows = ${countMnMDF.count()}\")\n",
    "    println()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb6d96c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-----+\n",
      "|State| Color|Total|\n",
      "+-----+------+-----+\n",
      "|   CA|Yellow| 1807|\n",
      "|   WA| Green| 1779|\n",
      "|   OR|Orange| 1743|\n",
      "|   TX| Green| 1737|\n",
      "|   TX|   Red| 1725|\n",
      "|   CA| Green| 1723|\n",
      "|   CO|Yellow| 1721|\n",
      "|   CA| Brown| 1718|\n",
      "|   CO| Green| 1713|\n",
      "|   NV|Orange| 1712|\n",
      "|   TX|Yellow| 1703|\n",
      "|   NV| Green| 1698|\n",
      "|   AZ| Brown| 1698|\n",
      "|   WY| Green| 1695|\n",
      "|   CO|  Blue| 1695|\n",
      "|   NM|   Red| 1690|\n",
      "|   AZ|Orange| 1689|\n",
      "|   NM|Yellow| 1688|\n",
      "|   NM| Brown| 1687|\n",
      "|   UT|Orange| 1684|\n",
      "+-----+------+-----+\n",
      "only showing top 20 rows\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "// Haciendo lo mismo usando tempViews y Spark SQL\n",
    "spark.sql(\"\"\"SELECT State, Color, count(*) as Total\n",
    "             FROM mnmDFView\n",
    "             GROUP BY State, Color\n",
    "             ORDER BY Total desc\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c513dd8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+----------+\n",
      "|State|Color |sum(Count)|\n",
      "+-----+------+----------+\n",
      "|CA   |Yellow|100956    |\n",
      "|WA   |Green |96486     |\n",
      "|CA   |Brown |95762     |\n",
      "|TX   |Green |95753     |\n",
      "|TX   |Red   |95404     |\n",
      "|CO   |Yellow|95038     |\n",
      "|NM   |Red   |94699     |\n",
      "|OR   |Orange|94514     |\n",
      "|WY   |Green |94339     |\n",
      "|NV   |Orange|93929     |\n",
      "+-----+------+----------+\n",
      "only showing top 10 rows\n",
      "\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sumMnMDF: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [State: string, Color: string ... 1 more field]\r\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sumMnMDF = mnmDF.select(\"State\", \"Color\", \"Count\")\n",
    "        .groupBy(\"State\", \"Color\")\n",
    "        .sum(\"Count\")\n",
    "        .orderBy(desc(\"sum(Count)\"))\n",
    "\n",
    "sumMnMDF.show(10,false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2e19bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+\n",
      "|State|Color |Suma  |\n",
      "+-----+------+------+\n",
      "|CA   |Yellow|100956|\n",
      "|WA   |Green |96486 |\n",
      "|CA   |Brown |95762 |\n",
      "|TX   |Green |95753 |\n",
      "|TX   |Red   |95404 |\n",
      "|CO   |Yellow|95038 |\n",
      "|NM   |Red   |94699 |\n",
      "|OR   |Orange|94514 |\n",
      "|WY   |Green |94339 |\n",
      "|NV   |Orange|93929 |\n",
      "+-----+------+------+\n",
      "only showing top 10 rows\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "// Haciendo lo mismo usando tempViews y Spark SQL\n",
    "spark.sql(\"\"\"SELECT State, Color, sum(Count) as Suma\n",
    "             FROM mnmDFView\n",
    "             GROUP BY State, Color\n",
    "             ORDER BY sum(Count) desc\"\"\").show(10,false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c24d886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-----+\n",
      "|State| Color|Total|\n",
      "+-----+------+-----+\n",
      "|   CA|Yellow| 1807|\n",
      "|   CA| Green| 1723|\n",
      "|   CA| Brown| 1718|\n",
      "|   CA|Orange| 1657|\n",
      "|   CA|   Red| 1656|\n",
      "|   CA|  Blue| 1603|\n",
      "+-----+------+-----+\n",
      "\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "caCountMnNDF: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [State: string, Color: string ... 1 more field]\r\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    // find the aggregate count for California by filtering\n",
    "\n",
    "val caCountMnNDF = mnmDF\n",
    " .select(\"State\", \"Color\", \"Count\")\n",
    " .where($\"State\" === \"CA\")\n",
    " .groupBy(\"State\", \"Color\")\n",
    " .agg(count(\"Count\").alias(\"Total\"))\n",
    " .orderBy(desc(\"Total\"))\n",
    "\n",
    "    // show the resulting aggregation for California\n",
    "    caCountMnNDF.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28f3618a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-----+\n",
      "|State| Color|Total|\n",
      "+-----+------+-----+\n",
      "|   CA|Yellow| 1807|\n",
      "|   CA| Green| 1723|\n",
      "|   CA| Brown| 1718|\n",
      "|   CA|Orange| 1657|\n",
      "|   CA|   Red| 1656|\n",
      "|   CA|  Blue| 1603|\n",
      "+-----+------+-----+\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "// Haciendo lo mismo usando tempViews y Spark SQL\n",
    "spark.sql(\"\"\"SELECT State, Color, count(*) as Total\n",
    "             FROM mnmDFView\n",
    "             WHERE State== 'CA'\n",
    "             GROUP BY State, Color\n",
    "             ORDER BY Total desc\"\"\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0c43d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+----------+\n",
      "|State|Color |sum(Count)|\n",
      "+-----+------+----------+\n",
      "|CA   |Yellow|100956    |\n",
      "|CA   |Brown |95762     |\n",
      "|CA   |Green |93505     |\n",
      "|CA   |Red   |91527     |\n",
      "|CA   |Orange|90311     |\n",
      "|CA   |Blue  |89123     |\n",
      "+-----+------+----------+\n",
      "\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "caSumMnNDF: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [State: string, Color: string ... 1 more field]\r\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    val caSumMnNDF = mnmDF.select(\"*\")\n",
    "      .where(col(\"State\") === \"CA\")\n",
    "      .groupBy(\"State\", \"Color\")\n",
    "      .sum(\"Count\")\n",
    "      .orderBy(desc(\"sum(Count)\"))\n",
    "\n",
    "caSumMnNDF.show(10,false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45c312a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+\n",
      "|State|Color |Suma  |\n",
      "+-----+------+------+\n",
      "|CA   |Yellow|100956|\n",
      "|CA   |Brown |95762 |\n",
      "|CA   |Green |93505 |\n",
      "|CA   |Red   |91527 |\n",
      "|CA   |Orange|90311 |\n",
      "|CA   |Blue  |89123 |\n",
      "+-----+------+------+\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "// Haciendo lo mismo usando tempViews y Spark SQL\n",
    "spark.sql(\"\"\"SELECT State, Color, sum(Count) as Suma\n",
    "             FROM mnmDFView\n",
    "             WHERE State == 'CA'\n",
    "             GROUP BY State, Color\n",
    "             ORDER BY Suma desc\"\"\").show(10, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "927e8849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-----------------+------+\n",
      "|Max|Min|              Avg|Cuenta|\n",
      "+---+---+-----------------+------+\n",
      "|100| 10|55.00090000900009| 99999|\n",
      "+---+---+-----------------+------+\n",
      "\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "caCountMnNDF: org.apache.spark.sql.DataFrame = [Max: int, Min: int ... 2 more fields]\r\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "     val caCountMnNDF = mnmDF.select(max(\"Count\") as \"Max\",min(\"Count\") as \"Min\",avg(\"Count\") as \"Avg\",count(\"*\") as \"Cuenta\")\n",
    "\n",
    "    caCountMnNDF.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a06a1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-----------------+------+\n",
      "|Max|Min|              Avg|Cuenta|\n",
      "+---+---+-----------------+------+\n",
      "|100| 10|55.00090000900009| 99999|\n",
      "+---+---+-----------------+------+\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "// Haciendo lo mismo usando tempViews y Spark SQL\n",
    "spark.sql(\"\"\"SELECT max(Count) as Max, min(Count) as Min, avg(Count) as Avg, count(*) as Cuenta\n",
    "             FROM mnmDFView\"\"\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "efb9d652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------+\n",
      "|value                                                                                         |\n",
      "+----------------------------------------------------------------------------------------------+\n",
      "|DON QUIJOTE DE LA MANCHA                                                                      |\n",
      "|Miguel de Cervantes Saavedra                                                                  |\n",
      "|                                                                                              |\n",
      "|PRIMERA PARTE                                                                                 |\n",
      "|CAPI?TULO 1: Que trata de la condicio?n y ejercicio del famoso hidalgo D. Quijote de la Mancha|\n",
      "+----------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "quijote: String = C:/Users/alvaro.romero/Big_Data/Ejercicios_Spark/el_quijote.txt\r\n",
       "qj_df: org.apache.spark.sql.DataFrame = [value: string]\r\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val quijote=\"C:/Users/alvaro.romero/Big_Data/Ejercicios_Spark/el_quijote.txt\"\n",
    "val qj_df = spark.read.format(\"text\")\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"inferSchema\", \"true\")\n",
    "        .load(quijote)\n",
    "qj_df.show(5,false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35618007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|DON QUIJOTE DE LA...|\n",
      "|Miguel de Cervant...|\n",
      "|                    |\n",
      "|       PRIMERA PARTE|\n",
      "|CAPI?TULO 1: Que ...|\n",
      "|En un lugar de la...|\n",
      "|Tuvo muchas veces...|\n",
      "|En resolucio?n, e...|\n",
      "|historia ma?s cie...|\n",
      "|Deci?a e?l, que e...|\n",
      "|En efecto, remata...|\n",
      "|Imagina?base el p...|\n",
      "|linaje y patria, ...|\n",
      "|Limpias, pues, su...|\n",
      "|Capi?tulo 2: Que ...|\n",
      "|Hechas, pues, est...|\n",
      "|Estos pensamiento...|\n",
      "|Con estos iba ens...|\n",
      "|Autores hay que d...|\n",
      "|muertos de hambre...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "qj_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9560ad42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|DON QUIJOTE DE LA...|\n",
      "|Miguel de Cervant...|\n",
      "|                    |\n",
      "|       PRIMERA PARTE|\n",
      "|CAPI?TULO 1: Que ...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "qj_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a31445cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res3: Long = 2186\r\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qj_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11b54db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res4: org.apache.spark.sql.Row = [DON QUIJOTE DE LA MANCHA]\r\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qj_df.first()\n",
    "\n",
    "// Devuelve la primera línea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "803a1aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res5: org.apache.spark.sql.Row = [DON QUIJOTE DE LA MANCHA]\r\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qj_df.head()\n",
    "\n",
    "// Devuelve la cabecera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e380b669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res6: Array[org.apache.spark.sql.Row] = Array([DON QUIJOTE DE LA MANCHA], [Miguel de Cervantes Saavedra], [], [PRIMERA PARTE], [CAPI?TULO 1: Que trata de la condicio?n y ejercicio del famoso hidalgo D. Quijote de la Mancha])\r\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qj_df.take(5)\n",
    "\n",
    "// Devuelve las 5 primeras líneas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc660ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
